{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "import os\n",
    "#os.chdir(path = {your path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basics\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chaey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chaey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\chaey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import nlp relevants\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# for bag-of-words (bow)\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>htmlBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Need For Work On Technical AI Alignment (I...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why I’m not working on {debate, RRM, ELK, natu...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;[For background &amp;amp; spelling out the acro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EIS II: What is “Interpretability”?</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;Part 2 of 12 in the&amp;nbsp;&lt;a href=\"https://w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Engineer’s Interpretability Sequence (EIS)...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;&lt;br&gt;Part 1 of 12 in the &lt;a href=\"https://ww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Notes on the Mathematics of LLM Architectures</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;From a mathematical point of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title author  \\\n",
       "0  The Need For Work On Technical AI Alignment (I...   None   \n",
       "1  Why I’m not working on {debate, RRM, ELK, natu...   None   \n",
       "2               EIS II: What is “Interpretability”?    None   \n",
       "3  The Engineer’s Interpretability Sequence (EIS)...   None   \n",
       "4      Notes on the Mathematics of LLM Architectures   None   \n",
       "\n",
       "                                            htmlBody  \n",
       "0                                                     \n",
       "1  <p>[For background &amp; spelling out the acro...  \n",
       "2  <p>Part 2 of 12 in the&nbsp;<a href=\"https://w...  \n",
       "3  <p><br>Part 1 of 12 in the <a href=\"https://ww...  \n",
       "4  <blockquote><p><i>From a mathematical point of...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "data = pd.read_json('posts.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETL:\n",
    "\n",
    "    # text normalization - stemming, lemmatization, stopwords\n",
    "    ps = PorterStemmer()\n",
    "    wordnet_lemmatizer = WordNetLemmatizer() \n",
    "    s_words = stopwords.words()\n",
    "    \n",
    "    \n",
    "    # normalization of question sentences\n",
    "    def _norm_sent(self, sent, rm_stopwords = False, stemming = True, lemmatization = False):\n",
    "        \n",
    "        # tokenize - sentence to word\n",
    "        words = word_tokenize(sent)\n",
    "        \n",
    "        # take if all characters in the string are alphabets and then decapitalize\n",
    "        sent = [w.lower() for w in words if w.isalpha()] \n",
    "\n",
    "        # remove stopwords\n",
    "        if rm_stopwords:\n",
    "          sent = [w for w in sent if w not in self.s_words]    \n",
    "\n",
    "        # apply lemmatization \n",
    "        if lemmatization:\n",
    "          sent = [self.wordnet_lemmatizer.lemmatize(w, pos = \"n\") for w in sent]\n",
    "          sent = [self.wordnet_lemmatizer.lemmatize(w, pos = \"v\") for w in sent]\n",
    "          sent = [self.wordnet_lemmatizer.lemmatize(w, pos = (\"a\")) for w in sent]\n",
    "\n",
    "        # apply stemming \n",
    "        if stemming:\n",
    "          sent = [self.ps.stem(w) for w in sent]\n",
    "\n",
    "        sent = \" \".join(sent)\n",
    "        return sent  \n",
    "    \n",
    "    \n",
    "    def norm_data(self, data):   \n",
    "        data.loc[:, \"title_processed\"] = data[\"title\"].apply(lambda x: self._norm_sent(x, rm_stopwords = True, lemmatization = True, stemming = True))\n",
    "        return data   \n",
    "    \n",
    "    \n",
    "    def bow_fit(self, corpus, type = \"tfidf\", max_features = 10000, ngram_range = (1,2)):\n",
    "        \n",
    "        if type == \"tfidf\": \n",
    "            self.tfidf_vectorizer = feature_extraction.text.TfidfVectorizer(max_features = max_features, ngram_range = ngram_range)\n",
    "            self.tfidf_vectorizer.fit(corpus[\"title\"])\n",
    "\n",
    "            # create a reverse mapping for the vocab\n",
    "            self.inv_tfidf_vectorizer_vocab = {}\n",
    "            \n",
    "            for label, ind in self.tfidf_vectorizer.vocabulary_.items():\n",
    "                self.inv_tfidf_vectorizer_vocab[ind] = label\n",
    "\n",
    "        else:\n",
    "            return NotImplementedError\n",
    "        \n",
    "        \n",
    "    def bow_transform(self, data, type = \"tfidf\"):\n",
    "        \n",
    "        if type == \"tfidf\":\n",
    "            return self.tfidf_vectorizer.transform(data[\"title\"])\n",
    "        \n",
    "        else:\n",
    "            return NotImplementedError\n",
    "\n",
    "    # save output\n",
    "    def save_vectorizers(self, path):\n",
    "\n",
    "        # make sure directory exists\n",
    "        os.makedirs(exist_ok= True, name=path)\n",
    "\n",
    "        if self.tfidf_vectorizer != None:\n",
    "            with open(os.path.join(path, \"tfidf_vectorizer.pkl\"), \"wb\") as tfidf_file:\n",
    "                pickle.dump(self.tfidf_vectorizer, tfidf_file) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl = ETL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = etl.norm_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>htmlBody</th>\n",
       "      <th>title_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Need For Work On Technical AI Alignment (I...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>work technic align intro explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why I’m not working on {debate, RRM, ELK, natu...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;[For background &amp;amp; spelling out the acro...</td>\n",
       "      <td>work debat rrm elk natur abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EIS II: What is “Interpretability”?</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;Part 2 of 12 in the&amp;nbsp;&lt;a href=\"https://w...</td>\n",
       "      <td>ei interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Engineer’s Interpretability Sequence (EIS)...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;&lt;br&gt;Part 1 of 12 in the &lt;a href=\"https://ww...</td>\n",
       "      <td>engin interpret sequenc ei intro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Notes on the Mathematics of LLM Architectures</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;From a mathematical point of...</td>\n",
       "      <td>note mathemat llm architectur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title author  \\\n",
       "0  The Need For Work On Technical AI Alignment (I...   None   \n",
       "1  Why I’m not working on {debate, RRM, ELK, natu...   None   \n",
       "2               EIS II: What is “Interpretability”?    None   \n",
       "3  The Engineer’s Interpretability Sequence (EIS)...   None   \n",
       "4      Notes on the Mathematics of LLM Architectures   None   \n",
       "\n",
       "                                            htmlBody  \\\n",
       "0                                                      \n",
       "1  <p>[For background &amp; spelling out the acro...   \n",
       "2  <p>Part 2 of 12 in the&nbsp;<a href=\"https://w...   \n",
       "3  <p><br>Part 1 of 12 in the <a href=\"https://ww...   \n",
       "4  <blockquote><p><i>From a mathematical point of...   \n",
       "\n",
       "                     title_processed  \n",
       "0   work technic align intro explain  \n",
       "1  work debat rrm elk natur abstract  \n",
       "2                       ei interpret  \n",
       "3   engin interpret sequenc ei intro  \n",
       "4      note mathemat llm architectur  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization - bag of words model\n",
    "etl.bow_fit(corpus = df, type = \"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl.save_vectorizers(path=\"sklearn_objects\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
